{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised classification\n",
    "\n",
    "In the data.csv there are letters (uppercases and lowercases) and numbers, 28x28 pixels in a row format.\n",
    "\n",
    "* First, you need to know which labels are which, meaning you need to visualize some data to realize which number labels represents a letter, or a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data_all.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df.e.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.,  0.,  3., 33., 30., 24., 40.,  5.,  8.,  2.,  4., 47.,  7.,\n",
       "       32., 60., 18., 46., 59., 12., 37., 53., 15.,  1.,  9., 38., 43.,\n",
       "       44., 19., 55.,  6., 58., 41., 20., 29., 28., 31., 42., 39., 25.,\n",
       "       49., 35., 14., 57., 34., 26., 61., 11., 13., 27., 51., 23., 10.,\n",
       "       22., 56., 48., 52., 16., 17., 54., 21., 50., 45.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.e.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/Cellar/ipython/7.8.0/libexec/vendor/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "numbers = df[df.e<=9]\n",
    "upper = df[df.e>9][df.e<=35]\n",
    "lower = df[df.e>35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(df.iloc[24][1:].values.reshape(28,28))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, try to train a classifier model to predict the uppercases. Use every single model you know for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.linear_model import SGDClassifier as SGDC \n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "logreg_model = LogReg(max_iter=500, n_jobs=-1)\n",
    "sgdc_model = SGDC(max_iter=500, n_jobs=-1)\n",
    "perceptron_model = Perceptron(max_iter=500, n_jobs=-1)\n",
    "\n",
    "models = [logreg_model, sgdc_model, perceptron_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Model accuracy: 0.7647152655925985\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=500, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Model accuracy: 0.6986760248843515\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=500, n_iter_no_change=5, n_jobs=-1,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Model accuracy: 0.7308980698676025\n"
     ]
    }
   ],
   "source": [
    "X = upper[upper.drop(columns=['e']).columns]\n",
    "y = upper.e\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Model accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try to do the same thing with lowercases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Model accuracy: 0.7400221729490022\n",
      "-----\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=500, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Model accuracy: 0.688839615668884\n",
      "-----\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=500, n_iter_no_change=5, n_jobs=-1,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Model accuracy: 0.6688839615668883\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X = lower[upper.drop(columns=['e']).columns]\n",
    "y = lower.e\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Model accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try to do the same thing with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=-1, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Model accuracy: 0.9247237569060773\n",
      "-----\n",
      "\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=500, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Model accuracy: 0.8798342541436464\n",
      "-----\n",
      "\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=500, n_iter_no_change=5, n_jobs=-1,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Model accuracy: 0.8920925414364641\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "X = numbers[upper.drop(columns=['e']).columns]\n",
    "y = numbers.e\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Model accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('-----')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
